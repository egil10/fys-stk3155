{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87907623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project 1: Regression Analysis and Resampling Methods\n",
    "# Part A: Ordinary Least Squares (OLS) for the Runge function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f7b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Runge function: f(x) = 1/(1+25x²)\n",
    "def runge_function(x):\n",
    "    \"\"\"Runge function for polynomial fitting analysis.\"\"\"\n",
    "    return 1 / (1 + 25 * x**2)\n",
    "\n",
    "# Generate dataset\n",
    "def generate_dataset(n_points=100, noise_level=0.1, x_range=(-1, 1)):\n",
    "    \"\"\"Generate dataset for the Runge function with optional noise.\"\"\"\n",
    "    x = np.linspace(x_range[0], x_range[1], n_points)\n",
    "    y_true = runge_function(x)\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0, noise_level, n_points)\n",
    "    y_noisy = y_true + noise\n",
    "    \n",
    "    return x, y_true, y_noisy\n",
    "\n",
    "# Test the function\n",
    "x_test, y_true_test, y_noisy_test = generate_dataset(n_points=100, noise_level=0.1)\n",
    "\n",
    "# Plot the original function\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_test, y_true_test, 'b-', label='True Runge function', linewidth=2)\n",
    "plt.plot(x_test, y_noisy_test, 'ro', label='Noisy data', markersize=4, alpha=0.7)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Runge Function: f(x) = 1/(1+25x²)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf2213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial features function (adapted from week 35)\n",
    "def polynomial_features(x, degree, intercept=True):\n",
    "    \"\"\"Create polynomial features matrix.\"\"\"\n",
    "    n = len(x)\n",
    "    if intercept:\n",
    "        X = np.ones((n, degree + 1))\n",
    "        for j in range(1, degree + 1):\n",
    "            X[:, j] = x**j\n",
    "    else:\n",
    "        X = np.zeros((n, degree))\n",
    "        for j in range(degree):\n",
    "            X[:, j] = x**(j + 1)\n",
    "    return X\n",
    "\n",
    "# OLS parameters function using pseudoinverse\n",
    "def ols_parameters(X, y):\n",
    "    \"\"\"Calculate OLS parameters using pseudoinverse.\"\"\"\n",
    "    return np.linalg.pinv(X) @ y\n",
    "\n",
    "# MSE and R² calculation functions\n",
    "def calculate_mse(y_true, y_pred):\n",
    "    \"\"\"Calculate Mean Squared Error.\"\"\"\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "def calculate_r2(y_true, y_pred):\n",
    "    \"\"\"Calculate R² score.\"\"\"\n",
    "    y_mean = np.mean(y_true)\n",
    "    ss_tot = np.sum((y_true - y_mean)**2)\n",
    "    ss_res = np.sum((y_true - y_pred)**2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "# Test the polynomial features function\n",
    "x_small = np.array([-1, 0, 1])\n",
    "X_test = polynomial_features(x_small, degree=3)\n",
    "print(\"Polynomial features test:\")\n",
    "print(\"x =\", x_small)\n",
    "print(\"X (degree=3):\")\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3e9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part A: OLS Analysis with different polynomial degrees\n",
    "# Generate larger dataset for analysis\n",
    "n_points = 200\n",
    "x, y_true, y_noisy = generate_dataset(n_points=n_points, noise_level=0.1)\n",
    "\n",
    "# Split data into training and test sets (80/20 split)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_noisy, test_size=0.2, random_state=42)\n",
    "\n",
    "# Analyze polynomial degrees from 1 to 15\n",
    "degrees = range(1, 16)\n",
    "train_mses = []\n",
    "test_mses = []\n",
    "train_r2s = []\n",
    "test_r2s = []\n",
    "parameters = []\n",
    "\n",
    "print(\"Polynomial Degree Analysis:\")\n",
    "print(\"Degree | Train MSE | Test MSE  | Train R²  | Test R²\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for degree in degrees:\n",
    "    # Create polynomial features\n",
    "    X_train = polynomial_features(x_train, degree)\n",
    "    X_test_poly = polynomial_features(x_test, degree)\n",
    "    \n",
    "    # Scale the features (important for higher degrees)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test_poly)\n",
    "    \n",
    "    # Calculate OLS parameters\n",
    "    beta = ols_parameters(X_train_scaled, y_train)\n",
    "    parameters.append(beta.copy())\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = X_train_scaled @ beta\n",
    "    y_test_pred = X_test_scaled @ beta\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mse = calculate_mse(y_train, y_train_pred)\n",
    "    test_mse = calculate_mse(y_test, y_test_pred)\n",
    "    train_r2 = calculate_r2(y_train, y_train_pred)\n",
    "    test_r2 = calculate_r2(y_test, y_test_pred)\n",
    "    \n",
    "    train_mses.append(train_mse)\n",
    "    test_mses.append(test_mse)\n",
    "    train_r2s.append(train_r2)\n",
    "    test_r2s.append(test_r2)\n",
    "    \n",
    "    print(f\"{degree:6d} | {train_mse:8.4f} | {test_mse:8.4f} | {train_r2:8.4f} | {test_r2:8.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
