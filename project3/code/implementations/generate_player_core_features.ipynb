{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading CSVs...\n",
            "Building per-game event features...\n",
            "Pre-computing cumulative statistics...\n",
            "Building datasets with cumulative and lag features...\n",
            "Saved datasets to: c:\\Users\\ofurn\\Dokumenter\\Github\\FYSSTK3155\\PROJECT 3\\Code\\processed_player_value\n",
            " - c:\\Users\\ofurn\\Dokumenter\\Github\\FYSSTK3155\\PROJECT 3\\Code\\processed_player_value\\cumlag_nn_tabular_dataset.csv\n",
            " - c:\\Users\\ofurn\\Dokumenter\\Github\\FYSSTK3155\\PROJECT 3\\Code\\processed_player_value\\cumlag_meta.csv\n",
            " - c:\\Users\\ofurn\\Dokumenter\\Github\\FYSSTK3155\\PROJECT 3\\Code\\processed_player_value\\cumlag_rnn_dataset.npz\n",
            "Tabular shape: (278558, 28)\n",
            "RNN X_seq: (278558, 20, 6) X_static: (278558, 12)\n",
            "\n",
            "Columns in tabular dataset:\n",
            "  - Static features: 12\n",
            "  - Cumulative features: 6\n",
            "  - Lag_10 features: 6\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# ----------------------------\n",
        "# Project paths (portable, notebook-safe)\n",
        "# ----------------------------\n",
        "try:\n",
        "    PROJECT_ROOT = Path(__file__).resolve().parent.parent\n",
        "except NameError:\n",
        "    # Running in Jupyter / interactive\n",
        "    PROJECT_ROOT = Path.cwd().parent\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / \"Data\"\n",
        "OUT_DIR = PROJECT_ROOT / \"Data_Processed\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "PLAYERS_CSV = DATA_DIR / \"players.csv\"\n",
        "VALUATIONS_CSV = DATA_DIR / \"player_valuations.csv\"\n",
        "EVENTS_CSV = DATA_DIR / \"game_events.csv\"\n",
        "\n",
        "# ----------------------------\n",
        "# Config\n",
        "# ----------------------------\n",
        "SEQ_LEN_T = 20\n",
        "LAG_MATCHES = 10  # Number of matches for lag features\n",
        "MIN_PRIOR_GAMES = 3\n",
        "MAX_SAMPLES = None  # set None to keep all\n",
        "USE_LOG_TARGET = True\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers\n",
        "# ----------------------------\n",
        "def safe_to_datetime(s):\n",
        "    return pd.to_datetime(s, errors=\"coerce\", utc=False)\n",
        "\n",
        "def compute_age_years(dob, ref_date):\n",
        "    \"\"\"Vectorized age computation\"\"\"\n",
        "    if pd.isna(dob) or pd.isna(ref_date):\n",
        "        return np.nan\n",
        "    return (ref_date - dob).days / 365.25\n",
        "\n",
        "def standardize_position(pos):\n",
        "    if pd.isna(pos):\n",
        "        return \"UNK\"\n",
        "    p = str(pos).upper()\n",
        "    if \"GOAL\" in p or p == \"GK\":\n",
        "        return \"GK\"\n",
        "    if \"DEF\" in p:\n",
        "        return \"DEF\"\n",
        "    if \"MID\" in p:\n",
        "        return \"MID\"\n",
        "    if \"ATT\" in p or \"FORW\" in p or \"WING\" in p or \"STRIK\" in p:\n",
        "        return \"ATT\"\n",
        "    return p[:10]\n",
        "\n",
        "def standardize_foot(foot):\n",
        "    if pd.isna(foot):\n",
        "        return \"UNK\"\n",
        "    f = str(foot).lower()\n",
        "    if f.startswith(\"right\"):\n",
        "        return \"R\"\n",
        "    if f.startswith(\"left\"):\n",
        "        return \"L\"\n",
        "    if \"both\" in f:\n",
        "        return \"B\"\n",
        "    return \"UNK\"\n",
        "\n",
        "def make_big5_flag(val_df):\n",
        "    \"\"\"\n",
        "    Big-5 leagues flag (England, Spain, Italy, Germany, France).\n",
        "    Uses player_valuations.csv column: player_club_domestic_competition_id\n",
        "    \"\"\"\n",
        "    BIG5_IDS = {\"GB1\", \"ES1\", \"IT1\", \"DE1\", \"FR1\"}\n",
        "    comp = val_df[\"player_club_domestic_competition_id\"].fillna(\"\").astype(str).str.upper()\n",
        "    val_df[\"is_big5_league\"] = comp.isin(BIG5_IDS).astype(np.float32)\n",
        "    return val_df\n",
        "\n",
        "# ----------------------------\n",
        "# Load data\n",
        "# ----------------------------\n",
        "print(\"Loading CSVs...\")\n",
        "players = pd.read_csv(PLAYERS_CSV)\n",
        "valuations = pd.read_csv(VALUATIONS_CSV)\n",
        "events = pd.read_csv(EVENTS_CSV, low_memory=False)\n",
        "\n",
        "players[\"date_of_birth\"] = safe_to_datetime(players[\"date_of_birth\"])\n",
        "valuations[\"date\"] = safe_to_datetime(valuations[\"date\"])\n",
        "events[\"date\"] = safe_to_datetime(events[\"date\"])\n",
        "\n",
        "valuations = valuations.dropna(subset=[\"player_id\", \"date\", \"market_value_in_eur\"])\n",
        "valuations[\"market_value_in_eur\"] = pd.to_numeric(\n",
        "    valuations[\"market_value_in_eur\"], errors=\"coerce\"\n",
        ")\n",
        "valuations = valuations.dropna(subset=[\"market_value_in_eur\"])\n",
        "valuations = valuations.sort_values([\"player_id\", \"date\"]).reset_index(drop=True)\n",
        "\n",
        "# ----------------------------\n",
        "# Static player features\n",
        "# ----------------------------\n",
        "players_static = players[\n",
        "    [\"player_id\", \"height_in_cm\", \"foot\", \"position\"]\n",
        "].copy()\n",
        "\n",
        "players_static[\"height_in_cm\"] = pd.to_numeric(\n",
        "    players_static[\"height_in_cm\"], errors=\"coerce\"\n",
        ")\n",
        "players_static[\"foot\"] = players_static[\"foot\"].apply(standardize_foot)\n",
        "players_static[\"pos_group\"] = players_static[\"position\"].apply(standardize_position)\n",
        "\n",
        "players_dob = players[[\"player_id\", \"date_of_birth\"]]\n",
        "\n",
        "static_ohe = pd.get_dummies(\n",
        "    players_static[[\"foot\", \"pos_group\"]].fillna(\"UNK\"),\n",
        "    prefix=[\"foot\", \"pos\"],\n",
        ")\n",
        "\n",
        "players_static_num = pd.concat(\n",
        "    [\n",
        "        players_static[[\"player_id\", \"height_in_cm\"]].reset_index(drop=True),\n",
        "        static_ohe.reset_index(drop=True),\n",
        "    ],\n",
        "    axis=1,\n",
        ").drop_duplicates(\"player_id\")\n",
        "\n",
        "# ----------------------------\n",
        "# Event-based per-game features (optimized)\n",
        "# ----------------------------\n",
        "print(\"Building per-game event features...\")\n",
        "\n",
        "ev = events.dropna(subset=[\"date\", \"game_id\"]).copy()\n",
        "ev[\"game_id\"] = pd.to_numeric(ev[\"game_id\"], errors=\"coerce\").astype(\"Int64\")\n",
        "ev[\"minute\"] = pd.to_numeric(ev[\"minute\"], errors=\"coerce\")\n",
        "\n",
        "desc = ev[\"description\"].fillna(\"\")\n",
        "is_goal = ev[\"type\"] == \"Goals\"\n",
        "is_yellow = (ev[\"type\"] == \"Cards\") & desc.str.contains(\"Yellow card\", case=False)\n",
        "is_red = (ev[\"type\"] == \"Cards\") & desc.str.contains(\"Red card\", case=False)\n",
        "is_sub = ev[\"type\"] == \"Substitutions\"\n",
        "\n",
        "def count_events(df, col=\"player_id\", name=\"count\"):\n",
        "    return (\n",
        "        df[[col, \"game_id\"]]\n",
        "        .dropna()\n",
        "        .groupby([col, \"game_id\"])\n",
        "        .size()\n",
        "        .rename(name)\n",
        "        .reset_index()\n",
        "        .rename(columns={col: \"player_id\"})\n",
        "    )\n",
        "\n",
        "goals = count_events(ev[is_goal], \"player_id\", \"goals\")\n",
        "assists = count_events(ev[is_goal], \"player_assist_id\", \"assists\")\n",
        "yellow = count_events(ev[is_yellow], \"player_id\", \"yellow_cards\")\n",
        "red = count_events(ev[is_red], \"player_id\", \"red_cards\")\n",
        "sub_in = count_events(ev[is_sub], \"player_in_id\", \"sub_in\")\n",
        "sub_out = count_events(ev[is_sub], \"player_id\", \"sub_out\")\n",
        "\n",
        "# Get game dates (optimized: group once)\n",
        "game_dates = ev.groupby(\"game_id\")[\"date\"].min().reset_index(name=\"game_date\")\n",
        "\n",
        "# Build per_game efficiently using merge\n",
        "pairs = pd.concat(\n",
        "    [goals, assists, yellow, red, sub_in, sub_out], axis=0\n",
        ")[[\"player_id\", \"game_id\"]].drop_duplicates()\n",
        "\n",
        "per_game = pairs.merge(game_dates, on=\"game_id\", how=\"left\")\n",
        "\n",
        "# Merge all event counts at once (more efficient)\n",
        "event_dfs = [goals, assists, yellow, red, sub_in, sub_out]\n",
        "for df in event_dfs:\n",
        "    per_game = per_game.merge(df, on=[\"player_id\", \"game_id\"], how=\"left\")\n",
        "\n",
        "per_game = per_game.fillna(0)\n",
        "per_game = per_game.sort_values([\"player_id\", \"game_date\"]).reset_index(drop=True)\n",
        "\n",
        "GAME_FEATURES = [\n",
        "    \"goals\", \"assists\", \"yellow_cards\", \"red_cards\", \"sub_in\", \"sub_out\"\n",
        "]\n",
        "\n",
        "# ----------------------------\n",
        "# Pre-compute cumulative sums for each player (OPTIMIZATION)\n",
        "# ----------------------------\n",
        "print(\"Pre-computing cumulative statistics...\")\n",
        "per_game_cum = per_game.copy()\n",
        "for feat in GAME_FEATURES:\n",
        "    per_game_cum[f\"cumulative_{feat}\"] = per_game.groupby(\"player_id\")[feat].cumsum().astype(np.float32)\n",
        "\n",
        "# ----------------------------\n",
        "# Build datasets with cumulative and lag features\n",
        "# ----------------------------\n",
        "print(\"Building datasets with cumulative and lag features...\")\n",
        "\n",
        "# Prepare valuations with static features\n",
        "val = valuations.merge(players_dob, on=\"player_id\", how=\"left\")\n",
        "# Vectorized age computation\n",
        "val[\"age_years\"] = val.apply(\n",
        "    lambda r: compute_age_years(r[\"date_of_birth\"], r[\"date\"]), axis=1\n",
        ")\n",
        "val = val.merge(players_static_num, on=\"player_id\", how=\"left\")\n",
        "val = make_big5_flag(val)\n",
        "\n",
        "val[\"y_raw\"] = pd.to_numeric(val[\"market_value_in_eur\"], errors=\"coerce\").astype(np.float32)\n",
        "val[\"y_log\"] = np.log1p(val[\"y_raw\"])\n",
        "\n",
        "static_cols = [\"height_in_cm\", \"age_years\", \"is_big5_league\"] + [\n",
        "    c for c in val.columns if c.startswith(\"foot_\") or c.startswith(\"pos_\")\n",
        "]\n",
        "\n",
        "# Pre-group for efficiency\n",
        "pgroups = {pid: g for pid, g in per_game_cum.groupby(\"player_id\")}\n",
        "vgroups = {pid: g for pid, g in val.groupby(\"player_id\")}\n",
        "\n",
        "X_seq, X_static, y_out, meta_rows, nn_rows = [], [], [], [], []\n",
        "\n",
        "# Process each player\n",
        "for pid, vg in vgroups.items():\n",
        "    if pid not in pgroups:\n",
        "        continue\n",
        "\n",
        "    gg = pgroups[pid].copy()\n",
        "    g_dates = gg[\"game_date\"].to_numpy()\n",
        "    g_feats = gg[GAME_FEATURES].to_numpy(dtype=np.float32)\n",
        "    \n",
        "    # Get cumulative features (exclude current row, so shift by 1)\n",
        "    cum_feats = gg[[f\"cumulative_{f}\" for f in GAME_FEATURES]].to_numpy(dtype=np.float32)\n",
        "    \n",
        "    # Get valuation dates for this player\n",
        "    val_dates = vg[\"date\"].to_numpy()\n",
        "    idxs = np.searchsorted(g_dates, val_dates, side=\"left\")\n",
        "\n",
        "    for i, n_before in enumerate(idxs):\n",
        "        if n_before < MIN_PRIOR_GAMES:\n",
        "            continue\n",
        "\n",
        "        # RNN sequence (last SEQ_LEN_T games)\n",
        "        seq = g_feats[max(0, n_before - SEQ_LEN_T):n_before]\n",
        "        if seq.shape[0] < SEQ_LEN_T:\n",
        "            seq = np.vstack([np.zeros((SEQ_LEN_T - seq.shape[0], seq.shape[1]), dtype=np.float32), seq])\n",
        "\n",
        "        # Target values\n",
        "        target_raw = float(vg.iloc[i][\"y_raw\"])\n",
        "        target_log = float(vg.iloc[i][\"y_log\"])\n",
        "\n",
        "        X_seq.append(seq)\n",
        "        X_static.append(vg.iloc[i][static_cols].to_numpy(dtype=np.float32))\n",
        "\n",
        "        if USE_LOG_TARGET:\n",
        "            y_out.append(target_log)\n",
        "        else:\n",
        "            y_out.append(target_raw)\n",
        "\n",
        "        meta_rows.append((pid, vg.iloc[i][\"date\"]))\n",
        "\n",
        "        # Cumulative features: total up to (and including) the last game before valuation\n",
        "        # n_before is the number of games before valuation, so index n_before-1 gives cumulative up to last game\n",
        "        if n_before > 0:\n",
        "            cum_values = cum_feats[n_before - 1].copy()  # Cumulative sum up to last game before valuation\n",
        "        else:\n",
        "            cum_values = np.zeros(len(GAME_FEATURES), dtype=np.float32)\n",
        "\n",
        "        # Lag features: last LAG_MATCHES games before valuation\n",
        "        lag_start = max(0, n_before - LAG_MATCHES)\n",
        "        lag_window = g_feats[lag_start:n_before]\n",
        "        \n",
        "        # Build row with cumulative and lag features\n",
        "        row_dict = {\n",
        "            \"player_id\": pid,\n",
        "            \"valuation_date\": vg.iloc[i][\"date\"],\n",
        "            \"y_raw\": target_raw,\n",
        "            \"y_log\": target_log,\n",
        "            **vg.iloc[i][static_cols].to_dict(),\n",
        "        }\n",
        "        \n",
        "        # Add cumulative features\n",
        "        for j, feat in enumerate(GAME_FEATURES):\n",
        "            row_dict[f\"cumulative_{feat}\"] = float(cum_values[j])\n",
        "        \n",
        "        # Add lag features (sum over last LAG_MATCHES games)\n",
        "        if len(lag_window) > 0:\n",
        "            lag_sums = lag_window.sum(axis=0)\n",
        "            for j, feat in enumerate(GAME_FEATURES):\n",
        "                row_dict[f\"lag_{LAG_MATCHES}_{feat}\"] = float(lag_sums[j])\n",
        "        else:\n",
        "            for feat in GAME_FEATURES:\n",
        "                row_dict[f\"lag_{LAG_MATCHES}_{feat}\"] = 0.0\n",
        "        \n",
        "        nn_rows.append(row_dict)\n",
        "\n",
        "X_seq = np.asarray(X_seq, dtype=np.float32)\n",
        "X_static = np.asarray(X_static, dtype=np.float32)\n",
        "y_out = np.asarray(y_out, dtype=np.float32)\n",
        "\n",
        "meta = pd.DataFrame(meta_rows, columns=[\"player_id\", \"valuation_date\"])\n",
        "tabular_df = pd.DataFrame(nn_rows)\n",
        "\n",
        "# Optional downsampling\n",
        "if MAX_SAMPLES and len(tabular_df) > MAX_SAMPLES:\n",
        "    idx = np.random.default_rng(0).choice(len(tabular_df), MAX_SAMPLES, replace=False)\n",
        "    tabular_df = tabular_df.iloc[idx]\n",
        "    X_seq = X_seq[idx]\n",
        "    X_static = X_static[idx]\n",
        "    y_out = y_out[idx]\n",
        "    meta = meta.iloc[idx]\n",
        "\n",
        "# ----------------------------\n",
        "# Save outputs\n",
        "# ----------------------------\n",
        "# Only saving the player_core_features.csv as requested\n",
        "print(f\"Saving to {OUT_DIR / 'player_core_features.csv'}...\")\n",
        "tabular_df.to_csv(OUT_DIR / \"player_core_features.csv\", index=False)\n",
        "\n",
        "print(f\"Saved dataset to: {OUT_DIR}\")\n",
        "print(f\" - {OUT_DIR / 'player_core_features.csv'}\")\n",
        "print(f\"Tabular shape: {tabular_df.shape}\")\n",
        "print(f\"\\nColumns in tabular dataset:\")\n",
        "print(f\"  - Static features: {len(static_cols)}\")\n",
        "print(f\"  - Cumulative features: {len(GAME_FEATURES)}\")\n",
        "print(f\"  - Lag_{LAG_MATCHES} features: {len(GAME_FEATURES)}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
