{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a37f62c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSVs...\n",
      "Building static player features...\n",
      "Building per-game event features...\n",
      "Preparing valuations...\n",
      "Building valuation-step sequences...\n",
      "Players used: 23700\n",
      "Samples: 337430\n",
      "X_seq: (337430, 5, 11) X_static: (337430, 10) y: (337430,)\n",
      "Final: (337430, 5, 11) (337430, 10) (337430,)\n",
      "Saved: c:\\Users\\johan\\OneDrive\\IN2010\\FYSSTK3155\\PROJECT 3\\Code\\Data_Processed\\valuation_seq_rnn_dataset.npz\n",
      "Seq features (F_SEQ): 11\n",
      "Static features: 10\n"
     ]
    }
   ],
   "source": [
    "# build_valuation_sequence_rnn_npz.py\n",
    "#\n",
    "# Builds an NPZ where the *sequence timesteps are valuation dates* (not games).\n",
    "# Each timestep summarizes what happened between two valuation dates.\n",
    "#\n",
    "# Output NPZ keys:\n",
    "#   - X_seq:      (N, T, F_seq) float32   sequence of valuation-interval features\n",
    "#   - X_static:   (N, F_static) float32   static player features (height + OHE foot/pos)\n",
    "#   - y:          (N,) float32            target = y_log at target valuation date\n",
    "#   - player_id:  (N,) int64\n",
    "#   - target_date:(N,) datetime64[ns]\n",
    "#\n",
    "# T = number of past valuation-steps used to predict the next valuation.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------\n",
    "# Paths (portable)\n",
    "# ----------------------------\n",
    "try:\n",
    "    PROJECT_ROOT = Path(__file__).resolve().parent.parent\n",
    "except NameError:\n",
    "    PROJECT_ROOT = Path.cwd().parent  # if running from a notebook folder\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"Data\"\n",
    "OUT_DIR = PROJECT_ROOT / \"Data_Processed\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PLAYERS_CSV = DATA_DIR / \"players.csv\"\n",
    "VALUATIONS_CSV = DATA_DIR / \"player_valuations.csv\"\n",
    "EVENTS_CSV = DATA_DIR / \"game_events.csv\"\n",
    "\n",
    "OUT_NPZ = OUT_DIR / \"valuation_seq_rnn_dataset.npz\"\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "T = 5                    # sequence length in valuation-steps\n",
    "MIN_VALUATIONS = T + 1   # need at least T+1 valuation dates to form 1 sample\n",
    "USE_LOG_TARGET = True    # log1p target\n",
    "CLIP_H_DAYS = True\n",
    "H_DAYS_MAX = 3650        # cap 10 years (optional)\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def safe_to_datetime(s):\n",
    "    return pd.to_datetime(s, errors=\"coerce\", utc=False)\n",
    "\n",
    "def to_int_player_id(df, col=\"player_id\"):\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[col]).copy()\n",
    "    df[col] = df[col].astype(np.int64)\n",
    "    return df\n",
    "\n",
    "def standardize_position(pos):\n",
    "    if pd.isna(pos):\n",
    "        return \"UNK\"\n",
    "    p = str(pos).upper()\n",
    "    if \"GOAL\" in p or p == \"GK\":\n",
    "        return \"GK\"\n",
    "    if \"DEF\" in p:\n",
    "        return \"DEF\"\n",
    "    if \"MID\" in p:\n",
    "        return \"MID\"\n",
    "    if \"ATT\" in p or \"FORW\" in p or \"WING\" in p or \"STRIK\" in p:\n",
    "        return \"ATT\"\n",
    "    return p[:10]\n",
    "\n",
    "def standardize_foot(foot):\n",
    "    if pd.isna(foot):\n",
    "        return \"UNK\"\n",
    "    f = str(foot).lower()\n",
    "    if f.startswith(\"right\"):\n",
    "        return \"R\"\n",
    "    if f.startswith(\"left\"):\n",
    "        return \"L\"\n",
    "    if \"both\" in f:\n",
    "        return \"B\"\n",
    "    return \"UNK\"\n",
    "\n",
    "def compute_age_years(dob, ref_date):\n",
    "    if pd.isna(dob) or pd.isna(ref_date):\n",
    "        return np.nan\n",
    "    return (ref_date - dob).days / 365.25\n",
    "\n",
    "def make_big5_flag(val_df):\n",
    "    # England, Spain, Italy, Germany, France (common Transfermarkt IDs)\n",
    "    BIG5_IDS = {\"GB1\", \"ES1\", \"IT1\", \"DE1\", \"FR1\"}\n",
    "    if \"player_club_domestic_competition_id\" not in val_df.columns:\n",
    "        val_df[\"is_big5_league\"] = 0.0\n",
    "        return val_df\n",
    "    comp = val_df[\"player_club_domestic_competition_id\"].fillna(\"\").astype(str).str.upper()\n",
    "    val_df[\"is_big5_league\"] = comp.isin(BIG5_IDS).astype(np.float32)\n",
    "    return val_df\n",
    "\n",
    "# ----------------------------\n",
    "# Load CSVs\n",
    "# ----------------------------\n",
    "print(\"Loading CSVs...\")\n",
    "players = pd.read_csv(PLAYERS_CSV, low_memory=False)\n",
    "valuations = pd.read_csv(VALUATIONS_CSV, low_memory=False)\n",
    "events = pd.read_csv(EVENTS_CSV, low_memory=False)\n",
    "\n",
    "players = to_int_player_id(players, \"player_id\")\n",
    "valuations = to_int_player_id(valuations, \"player_id\")\n",
    "\n",
    "players[\"date_of_birth\"] = safe_to_datetime(players.get(\"date_of_birth\"))\n",
    "valuations[\"date\"] = safe_to_datetime(valuations.get(\"date\"))\n",
    "\n",
    "events[\"date\"] = safe_to_datetime(events.get(\"date\"))\n",
    "events[\"game_id\"] = pd.to_numeric(events.get(\"game_id\"), errors=\"coerce\")\n",
    "events = events.dropna(subset=[\"date\", \"game_id\"]).copy()\n",
    "events[\"game_id\"] = events[\"game_id\"].astype(np.int64)\n",
    "\n",
    "# Make sure event player columns are numeric where present\n",
    "for c in [\"player_id\", \"player_assist_id\", \"player_in_id\"]:\n",
    "    if c in events.columns:\n",
    "        events[c] = pd.to_numeric(events[c], errors=\"coerce\")\n",
    "\n",
    "# Clean valuations\n",
    "valuations = valuations.dropna(subset=[\"date\", \"market_value_in_eur\"]).copy()\n",
    "valuations[\"market_value_in_eur\"] = pd.to_numeric(valuations[\"market_value_in_eur\"], errors=\"coerce\")\n",
    "valuations = valuations.dropna(subset=[\"market_value_in_eur\"]).copy()\n",
    "valuations = valuations.sort_values([\"player_id\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Build static player features (X_static)\n",
    "# ----------------------------\n",
    "print(\"Building static player features...\")\n",
    "\n",
    "pstat = players[[\"player_id\", \"height_in_cm\", \"foot\", \"position\", \"date_of_birth\"]].copy()\n",
    "pstat[\"height_in_cm\"] = pd.to_numeric(pstat[\"height_in_cm\"], errors=\"coerce\")\n",
    "pstat[\"foot\"] = pstat[\"foot\"].apply(standardize_foot)\n",
    "pstat[\"pos_group\"] = pstat[\"position\"].apply(standardize_position)\n",
    "\n",
    "static_ohe = pd.get_dummies(\n",
    "    pstat[[\"foot\", \"pos_group\"]].fillna(\"UNK\"),\n",
    "    prefix=[\"foot\", \"pos\"],\n",
    ")\n",
    "\n",
    "pstat_num = pd.concat(\n",
    "    [\n",
    "        pstat[[\"player_id\", \"height_in_cm\", \"date_of_birth\"]].reset_index(drop=True),\n",
    "        static_ohe.reset_index(drop=True),\n",
    "    ],\n",
    "    axis=1,\n",
    ").drop_duplicates(\"player_id\")\n",
    "\n",
    "static_cols = [\"height_in_cm\"] + [c for c in pstat_num.columns if c.startswith(\"foot_\") or c.startswith(\"pos_\")]\n",
    "pstat_num[static_cols] = pstat_num[static_cols].fillna(0.0)\n",
    "\n",
    "# Make a lookup dict for speed\n",
    "pstat_lookup = {}\n",
    "for _, row in pstat_num.iterrows():\n",
    "    pid = int(row[\"player_id\"])\n",
    "    pstat_lookup[pid] = (\n",
    "        float(row.get(\"height_in_cm\", 0.0)),\n",
    "        row[static_cols[1:]].to_numpy(dtype=np.float32),  # OHE part\n",
    "        row.get(\"date_of_birth\", pd.NaT),\n",
    "    )\n",
    "\n",
    "# ----------------------------\n",
    "# Build per-game event counts per player (for interval aggregation)\n",
    "# ----------------------------\n",
    "print(\"Building per-game event features...\")\n",
    "\n",
    "desc = events.get(\"description\", pd.Series([\"\"] * len(events))).fillna(\"\")\n",
    "etype = events.get(\"type\", pd.Series([\"\"] * len(events)))\n",
    "\n",
    "is_goal = etype == \"Goals\"\n",
    "is_yellow = (etype == \"Cards\") & desc.str.contains(\"Yellow card\", case=False, na=False)\n",
    "is_red = (etype == \"Cards\") & desc.str.contains(\"Red card\", case=False, na=False)\n",
    "is_sub = etype == \"Substitutions\"\n",
    "\n",
    "def count_events(df, col, name):\n",
    "    if col not in df.columns:\n",
    "        return pd.DataFrame(columns=[\"player_id\", \"game_id\", name])\n",
    "    tmp = df[[col, \"game_id\"]].dropna().copy()\n",
    "    tmp[col] = pd.to_numeric(tmp[col], errors=\"coerce\")\n",
    "    tmp = tmp.dropna(subset=[col])\n",
    "    tmp[col] = tmp[col].astype(np.int64)\n",
    "    out = (\n",
    "        tmp.groupby([col, \"game_id\"])\n",
    "        .size()\n",
    "        .rename(name)\n",
    "        .reset_index()\n",
    "        .rename(columns={col: \"player_id\"})\n",
    "    )\n",
    "    return out\n",
    "\n",
    "goals = count_events(events[is_goal], \"player_id\", \"goals\")\n",
    "assists = count_events(events[is_goal], \"player_assist_id\", \"assists\")\n",
    "yellow = count_events(events[is_yellow], \"player_id\", \"yellow_cards\")\n",
    "red = count_events(events[is_red], \"player_id\", \"red_cards\")\n",
    "sub_in = count_events(events[is_sub], \"player_in_id\", \"sub_in\")\n",
    "sub_out = count_events(events[is_sub], \"player_id\", \"sub_out\")\n",
    "\n",
    "game_dates = events.groupby(\"game_id\")[\"date\"].min().reset_index(name=\"game_date\")\n",
    "\n",
    "pairs = pd.concat([goals, assists, yellow, red, sub_in, sub_out], axis=0)[[\"player_id\", \"game_id\"]]\n",
    "pairs = pairs.dropna().drop_duplicates()\n",
    "\n",
    "per_game = pairs.merge(game_dates, on=\"game_id\", how=\"left\")\n",
    "\n",
    "for df in [goals, assists, yellow, red, sub_in, sub_out]:\n",
    "    per_game = per_game.merge(df, on=[\"player_id\", \"game_id\"], how=\"left\")\n",
    "\n",
    "per_game = per_game.fillna(0.0)\n",
    "per_game = per_game.dropna(subset=[\"game_date\"]).copy()\n",
    "per_game = per_game.sort_values([\"player_id\", \"game_date\"]).reset_index(drop=True)\n",
    "\n",
    "GAME_FEATURES = [\"goals\", \"assists\", \"yellow_cards\", \"red_cards\", \"sub_in\", \"sub_out\"]\n",
    "\n",
    "# Group per player for aggregation\n",
    "pgroups = {pid: g.reset_index(drop=True) for pid, g in per_game.groupby(\"player_id\")}\n",
    "\n",
    "# ----------------------------\n",
    "# Prepare valuations with useful columns\n",
    "# ----------------------------\n",
    "print(\"Preparing valuations...\")\n",
    "val = valuations.copy()\n",
    "val = make_big5_flag(val)\n",
    "\n",
    "val[\"y_raw\"] = val[\"market_value_in_eur\"].astype(np.float32)\n",
    "val[\"y_log\"] = np.log1p(val[\"y_raw\"]).astype(np.float32)\n",
    "\n",
    "# We'll compute age at valuation time using DOB from players\n",
    "# Build valuation groups per player\n",
    "vgroups = {pid: g.sort_values(\"date\").reset_index(drop=True) for pid, g in val.groupby(\"player_id\")}\n",
    "\n",
    "# ----------------------------\n",
    "# Build valuation-step sequences\n",
    "# ----------------------------\n",
    "print(\"Building valuation-step sequences...\")\n",
    "\n",
    "X_seq_list = []\n",
    "X_static_list = []\n",
    "y_list = []\n",
    "pid_list = []\n",
    "target_date_list = []\n",
    "\n",
    "# Each timestep feature vector (F_seq):\n",
    "# [prev_y_log, H_days, num_games, goals_sum, assists_sum, yellow_sum, red_sum, sub_in_sum, sub_out_sum, age_prev, big5_prev]\n",
    "# = 1 + 1 + 1 + 6 + 1 + 1 = 11\n",
    "F_SEQ = 11\n",
    "\n",
    "def get_interval_sums_for_player(pid, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Sum GAME_FEATURES for games with (start_date, end_date] for a given player.\n",
    "    Uses cumulative sums for speed.\n",
    "    \"\"\"\n",
    "    g = pgroups.get(pid)\n",
    "    if g is None or len(g) == 0:\n",
    "        return 0, np.zeros(len(GAME_FEATURES), dtype=np.float32)\n",
    "\n",
    "    g_dates = g[\"game_date\"].to_numpy()\n",
    "    feats = g[GAME_FEATURES].to_numpy(dtype=np.float32)\n",
    "\n",
    "    # cumulative sums (prefix)\n",
    "    csum = np.cumsum(feats, axis=0)\n",
    "    # use side='right' to include games on the same date as end_date\n",
    "    idx_end = np.searchsorted(g_dates, np.datetime64(end_date), side=\"right\")\n",
    "    idx_start = np.searchsorted(g_dates, np.datetime64(start_date), side=\"right\")\n",
    "\n",
    "    num_games = int(max(0, idx_end - idx_start))\n",
    "    if num_games == 0:\n",
    "        return 0, np.zeros(len(GAME_FEATURES), dtype=np.float32)\n",
    "\n",
    "    end_vec = csum[idx_end - 1]\n",
    "    start_vec = csum[idx_start - 1] if idx_start > 0 else np.zeros(len(GAME_FEATURES), dtype=np.float32)\n",
    "    sums = (end_vec - start_vec).astype(np.float32)\n",
    "    return num_games, sums\n",
    "\n",
    "n_players_used = 0\n",
    "n_samples = 0\n",
    "\n",
    "for pid, vg in vgroups.items():\n",
    "    if pid not in pstat_lookup:\n",
    "        continue\n",
    "    if pid not in pgroups:\n",
    "        continue\n",
    "\n",
    "    if len(vg) < MIN_VALUATIONS:\n",
    "        continue\n",
    "\n",
    "    height, ohe_vec, dob = pstat_lookup[pid]\n",
    "    # Build a list of valuation-step input vectors for this player\n",
    "    # step i predicts y_i from info at i-1 and games (t_{i-1}, t_i]\n",
    "    step_feats = []\n",
    "    step_targets = []\n",
    "    step_target_dates = []\n",
    "\n",
    "    for i in range(1, len(vg)):\n",
    "        d_prev = vg.loc[i - 1, \"date\"]\n",
    "        d_curr = vg.loc[i, \"date\"]\n",
    "\n",
    "        y_prev_log = float(vg.loc[i - 1, \"y_log\"])\n",
    "        y_curr_log = float(vg.loc[i, \"y_log\"])\n",
    "\n",
    "        H_days = (d_curr - d_prev).days\n",
    "        if pd.isna(H_days):\n",
    "            continue\n",
    "        H_days = int(H_days)\n",
    "        if H_days <= 0:\n",
    "            # skip weird duplicates/out-of-order\n",
    "            continue\n",
    "        if CLIP_H_DAYS:\n",
    "            H_days = int(min(H_days, H_DAYS_MAX))\n",
    "\n",
    "        big5_prev = float(vg.loc[i - 1, \"is_big5_league\"])\n",
    "\n",
    "        age_prev = compute_age_years(dob, d_prev)\n",
    "        if pd.isna(age_prev):\n",
    "            age_prev = 0.0\n",
    "\n",
    "        num_games, sums = get_interval_sums_for_player(pid, d_prev, d_curr)\n",
    "\n",
    "        feat_vec = np.zeros(F_SEQ, dtype=np.float32)\n",
    "        feat_vec[0] = y_prev_log\n",
    "        feat_vec[1] = float(H_days)\n",
    "        feat_vec[2] = float(num_games)\n",
    "        feat_vec[3:3+len(GAME_FEATURES)] = sums\n",
    "        feat_vec[9] = float(age_prev)\n",
    "        feat_vec[10] = float(big5_prev)\n",
    "\n",
    "        step_feats.append(feat_vec)\n",
    "        step_targets.append(y_curr_log if USE_LOG_TARGET else float(vg.loc[i, \"y_raw\"]))\n",
    "        step_target_dates.append(d_curr)\n",
    "\n",
    "    if len(step_feats) < T:\n",
    "        continue\n",
    "\n",
    "    step_feats = np.asarray(step_feats, dtype=np.float32)\n",
    "    step_targets = np.asarray(step_targets, dtype=np.float32)\n",
    "\n",
    "    # Static vector: [height] + OHE foot/pos\n",
    "    static_vec = np.concatenate([[np.float32(height)], ohe_vec.astype(np.float32)], axis=0).astype(np.float32)\n",
    "\n",
    "    # Create samples: for each target index k, take last T steps ending at k\n",
    "    # step_feats[k] predicts step_targets[k]\n",
    "    for k in range(T - 1, len(step_feats)):\n",
    "        seq = step_feats[k - (T - 1) : k + 1]  # shape (T, F_SEQ)\n",
    "        y_tgt = step_targets[k]\n",
    "        tgt_date = step_target_dates[k]\n",
    "\n",
    "        X_seq_list.append(seq)\n",
    "        X_static_list.append(static_vec)\n",
    "        y_list.append(y_tgt)\n",
    "        pid_list.append(pid)\n",
    "        target_date_list.append(tgt_date)\n",
    "        n_samples += 1\n",
    "\n",
    "    n_players_used += 1\n",
    "\n",
    "X_seq = np.asarray(X_seq_list, dtype=np.float32)\n",
    "X_static = np.asarray(X_static_list, dtype=np.float32)\n",
    "y_out = np.asarray(y_list, dtype=np.float32)\n",
    "\n",
    "player_id_arr = np.asarray(pid_list, dtype=np.int64)\n",
    "target_date_arr = np.asarray(pd.to_datetime(target_date_list).to_numpy(), dtype=\"datetime64[ns]\")\n",
    "\n",
    "print(\"Players used:\", n_players_used)\n",
    "print(\"Samples:\", n_samples)\n",
    "print(\"X_seq:\", X_seq.shape, \"X_static:\", X_static.shape, \"y:\", y_out.shape)\n",
    "\n",
    "# Final safety: remove any non-finite\n",
    "good = (\n",
    "    np.isfinite(X_seq).all(axis=(1,2)) &\n",
    "    np.isfinite(X_static).all(axis=1) &\n",
    "    np.isfinite(y_out)\n",
    ")\n",
    "if (~good).sum() > 0:\n",
    "    print(\"Dropping non-finite samples:\", int((~good).sum()))\n",
    "    X_seq = X_seq[good]\n",
    "    X_static = X_static[good]\n",
    "    y_out = y_out[good]\n",
    "    player_id_arr = player_id_arr[good]\n",
    "    target_date_arr = target_date_arr[good]\n",
    "\n",
    "print(\"Final:\", X_seq.shape, X_static.shape, y_out.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# Save NPZ\n",
    "# ----------------------------\n",
    "np.savez_compressed(\n",
    "    OUT_NPZ,\n",
    "    X_seq=X_seq,\n",
    "    X_static=X_static,\n",
    "    y=y_out,\n",
    "    player_id=player_id_arr,\n",
    "    target_date=target_date_arr,\n",
    ")\n",
    "\n",
    "print(\"Saved:\", OUT_NPZ)\n",
    "print(\"Seq features (F_SEQ):\", F_SEQ)\n",
    "print(\"Static features:\", X_static.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26243f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
