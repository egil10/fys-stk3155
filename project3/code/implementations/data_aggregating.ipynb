{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1748fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSVs...\n",
      "Building per-game event features...\n",
      "Building NN and RNN datasets...\n",
      "Saved datasets to: c:\\Users\\ofurn\\Dokumenter\\Github\\FYSSTK3155\\PROJECT 3\\Code\\processed_player_value\n",
      " - c:\\Users\\ofurn\\Dokumenter\\Github\\FYSSTK3155\\PROJECT 3\\Code\\processed_player_value\\nn_tabular_dataset.csv\n",
      " - c:\\Users\\ofurn\\Dokumenter\\Github\\FYSSTK3155\\PROJECT 3\\Code\\processed_player_value\\meta.csv\n",
      " - c:\\Users\\ofurn\\Dokumenter\\Github\\FYSSTK3155\\PROJECT 3\\Code\\processed_player_value\\rnn_dataset.npz\n",
      "Tabular shape: (278558, 28)\n",
      "RNN X_seq: (278558, 20, 6) X_static: (278558, 12)\n"
     ]
    }
   ],
   "source": [
    "# dataset_build_player_value.py\n",
    "# Portable version using pathlib (Mac / Linux / Windows safe)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------\n",
    "# Project paths (portable, notebook-safe)\n",
    "# ----------------------------\n",
    "try:\n",
    "    PROJECT_ROOT = Path(__file__).resolve().parent.parent\n",
    "except NameError:\n",
    "    # Running in Jupyter / interactive\n",
    "    PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"Data\"\n",
    "OUT_DIR = PROJECT_ROOT / \"Data_Processed\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PLAYERS_CSV = DATA_DIR / \"players.csv\"\n",
    "VALUATIONS_CSV = DATA_DIR / \"player_valuations.csv\"\n",
    "EVENTS_CSV = DATA_DIR / \"game_events.csv\"\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "SEQ_LEN_T = 20\n",
    "NN_WINDOW_W = 20\n",
    "MIN_PRIOR_GAMES = 3\n",
    "MAX_SAMPLES = None  # set None to keep all\n",
    "USE_LOG_TARGET = True\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def safe_to_datetime(s):\n",
    "    return pd.to_datetime(s, errors=\"coerce\", utc=False)\n",
    "\n",
    "def compute_age_years(dob, ref_date):\n",
    "    if pd.isna(dob) or pd.isna(ref_date):\n",
    "        return np.nan\n",
    "    return (ref_date - dob).days / 365.25\n",
    "\n",
    "def standardize_position(pos):\n",
    "    if pd.isna(pos):\n",
    "        return \"UNK\"\n",
    "    p = str(pos).upper()\n",
    "    if \"GOAL\" in p or p == \"GK\":\n",
    "        return \"GK\"\n",
    "    if \"DEF\" in p:\n",
    "        return \"DEF\"\n",
    "    if \"MID\" in p:\n",
    "        return \"MID\"\n",
    "    if \"ATT\" in p or \"FORW\" in p or \"WING\" in p or \"STRIK\" in p:\n",
    "        return \"ATT\"\n",
    "    return p[:10]\n",
    "\n",
    "def standardize_foot(foot):\n",
    "    if pd.isna(foot):\n",
    "        return \"UNK\"\n",
    "    f = str(foot).lower()\n",
    "    if f.startswith(\"right\"):\n",
    "        return \"R\"\n",
    "    if f.startswith(\"left\"):\n",
    "        return \"L\"\n",
    "    if \"both\" in f:\n",
    "        return \"B\"\n",
    "    return \"UNK\"\n",
    "\n",
    "# Add this helper near your other helpers\n",
    "def make_big5_flag(val_df):\n",
    "    \"\"\"\n",
    "    Big-5 leagues flag (England, Spain, Italy, Germany, France).\n",
    "    Uses player_valuations.csv column: player_club_domestic_competition_id\n",
    "\n",
    "    Works for common IDs like:\n",
    "      GB1 (Premier League), ES1 (LaLiga), IT1 (Serie A), DE1 (Bundesliga), FR1 (Ligue 1)\n",
    "\n",
    "    If your dataset uses different codes, just extend BIG5_IDS.\n",
    "    \"\"\"\n",
    "    BIG5_IDS = {\"GB1\", \"ES1\", \"IT1\", \"DE1\", \"FR1\"}\n",
    "\n",
    "    comp = val_df[\"player_club_domestic_competition_id\"].fillna(\"\").astype(str).str.upper()\n",
    "    val_df[\"is_big5_league\"] = comp.isin(BIG5_IDS).astype(np.float32)\n",
    "    return val_df\n",
    "\n",
    "# ----------------------------\n",
    "# Load data\n",
    "# ----------------------------\n",
    "print(\"Loading CSVs...\")\n",
    "players = pd.read_csv(PLAYERS_CSV)\n",
    "valuations = pd.read_csv(VALUATIONS_CSV)\n",
    "events = pd.read_csv(EVENTS_CSV, low_memory=False)\n",
    "\n",
    "players[\"date_of_birth\"] = safe_to_datetime(players[\"date_of_birth\"])\n",
    "valuations[\"date\"] = safe_to_datetime(valuations[\"date\"])\n",
    "events[\"date\"] = safe_to_datetime(events[\"date\"])\n",
    "\n",
    "valuations = valuations.dropna(subset=[\"player_id\", \"date\", \"market_value_in_eur\"])\n",
    "valuations[\"market_value_in_eur\"] = pd.to_numeric(\n",
    "    valuations[\"market_value_in_eur\"], errors=\"coerce\"\n",
    ")\n",
    "valuations = valuations.dropna(subset=[\"market_value_in_eur\"])\n",
    "valuations = valuations.sort_values([\"player_id\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Static player features\n",
    "# ----------------------------\n",
    "players_static = players[\n",
    "    [\"player_id\", \"height_in_cm\", \"foot\", \"position\"]\n",
    "].copy()\n",
    "\n",
    "players_static[\"height_in_cm\"] = pd.to_numeric(\n",
    "    players_static[\"height_in_cm\"], errors=\"coerce\"\n",
    ")\n",
    "players_static[\"foot\"] = players_static[\"foot\"].apply(standardize_foot)\n",
    "players_static[\"pos_group\"] = players_static[\"position\"].apply(standardize_position)\n",
    "\n",
    "players_dob = players[[\"player_id\", \"date_of_birth\"]]\n",
    "\n",
    "static_ohe = pd.get_dummies(\n",
    "    players_static[[\"foot\", \"pos_group\"]].fillna(\"UNK\"),\n",
    "    prefix=[\"foot\", \"pos\"],\n",
    ")\n",
    "\n",
    "players_static_num = pd.concat(\n",
    "    [\n",
    "        players_static[[\"player_id\", \"height_in_cm\"]].reset_index(drop=True),\n",
    "        static_ohe.reset_index(drop=True),\n",
    "    ],\n",
    "    axis=1,\n",
    ").drop_duplicates(\"player_id\")\n",
    "\n",
    "# ----------------------------\n",
    "# Event-based per-game features\n",
    "# ----------------------------\n",
    "print(\"Building per-game event features...\")\n",
    "\n",
    "ev = events.dropna(subset=[\"date\", \"game_id\"]).copy()\n",
    "ev[\"game_id\"] = pd.to_numeric(ev[\"game_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "ev[\"minute\"] = pd.to_numeric(ev[\"minute\"], errors=\"coerce\")\n",
    "\n",
    "desc = ev[\"description\"].fillna(\"\")\n",
    "is_goal = ev[\"type\"] == \"Goals\"\n",
    "is_yellow = (ev[\"type\"] == \"Cards\") & desc.str.contains(\"Yellow card\", case=False)\n",
    "is_red = (ev[\"type\"] == \"Cards\") & desc.str.contains(\"Red card\", case=False)\n",
    "is_sub = ev[\"type\"] == \"Substitutions\"\n",
    "\n",
    "def count_events(df, col=\"player_id\", name=\"count\"):\n",
    "    return (\n",
    "        df[[col, \"game_id\"]]\n",
    "        .dropna()\n",
    "        .groupby([col, \"game_id\"])\n",
    "        .size()\n",
    "        .rename(name)\n",
    "        .reset_index()\n",
    "        .rename(columns={col: \"player_id\"})\n",
    "    )\n",
    "\n",
    "goals = count_events(ev[is_goal], \"player_id\", \"goals\")\n",
    "assists = count_events(ev[is_goal], \"player_assist_id\", \"assists\")\n",
    "yellow = count_events(ev[is_yellow], \"player_id\", \"yellow_cards\")\n",
    "red = count_events(ev[is_red], \"player_id\", \"red_cards\")\n",
    "sub_in = count_events(ev[is_sub], \"player_in_id\", \"sub_in\")\n",
    "sub_out = count_events(ev[is_sub], \"player_id\", \"sub_out\")\n",
    "\n",
    "game_dates = (\n",
    "    ev.groupby(\"game_id\")[\"date\"].min().reset_index(name=\"game_date\")\n",
    ")\n",
    "\n",
    "pairs = pd.concat(\n",
    "    [goals, assists, yellow, red, sub_in, sub_out], axis=0\n",
    ")[[\"player_id\", \"game_id\"]].drop_duplicates()\n",
    "\n",
    "per_game = pairs.merge(game_dates, on=\"game_id\", how=\"left\")\n",
    "\n",
    "for df in [goals, assists, yellow, red, sub_in, sub_out]:\n",
    "    per_game = per_game.merge(df, on=[\"player_id\", \"game_id\"], how=\"left\")\n",
    "\n",
    "per_game = per_game.fillna(0)\n",
    "per_game = per_game.sort_values([\"player_id\", \"game_date\"]).reset_index(drop=True)\n",
    "\n",
    "GAME_FEATURES = [\n",
    "    \"goals\", \"assists\", \"yellow_cards\", \"red_cards\", \"sub_in\", \"sub_out\"\n",
    "]\n",
    "\n",
    "# ----------------------------\n",
    "# Build NN + RNN datasets\n",
    "# ----------------------------\n",
    "print(\"Building NN and RNN datasets...\")\n",
    "\n",
    "val = valuations.merge(players_dob, on=\"player_id\", how=\"left\")\n",
    "val[\"age_years\"] = val.apply(\n",
    "    lambda r: compute_age_years(r[\"date_of_birth\"], r[\"date\"]), axis=1\n",
    ")\n",
    "val = val.merge(players_static_num, on=\"player_id\", how=\"left\")\n",
    "val = make_big5_flag(val)\n",
    "\n",
    "\n",
    "val[\"y_raw\"] = pd.to_numeric(val[\"market_value_in_eur\"], errors=\"coerce\").astype(np.float32)\n",
    "val[\"y_log\"] = np.log1p(val[\"y_raw\"])\n",
    "\n",
    "static_cols = [\"height_in_cm\", \"age_years\", \"is_big5_league\"] + [\n",
    "    c for c in val.columns if c.startswith(\"foot_\") or c.startswith(\"pos_\")\n",
    "]\n",
    "\n",
    "\n",
    "X_seq, X_static, y_out, meta_rows, nn_rows = [], [], [], [], []\n",
    "\n",
    "pgroups = {pid: g for pid, g in per_game.groupby(\"player_id\")}\n",
    "vgroups = {pid: g for pid, g in val.groupby(\"player_id\")}\n",
    "\n",
    "for pid, vg in vgroups.items():\n",
    "    if pid not in pgroups:\n",
    "        continue\n",
    "\n",
    "    gg = pgroups[pid]\n",
    "    g_dates = gg[\"game_date\"].to_numpy()\n",
    "    g_feats = gg[GAME_FEATURES].to_numpy(dtype=np.float32)\n",
    "\n",
    "    idxs = np.searchsorted(g_dates, vg[\"date\"].to_numpy(), side=\"left\")\n",
    "\n",
    "    for i, n_before in enumerate(idxs):\n",
    "        if n_before < MIN_PRIOR_GAMES:\n",
    "            continue\n",
    "\n",
    "        seq = g_feats[max(0, n_before - SEQ_LEN_T):n_before]\n",
    "        if seq.shape[0] < SEQ_LEN_T:\n",
    "            seq = np.vstack([np.zeros((SEQ_LEN_T - seq.shape[0], seq.shape[1])), seq])\n",
    "\n",
    "        # -------- TARGET (CORRECTLY ALIGNED) --------\n",
    "        target_raw = float(vg.iloc[i][\"y_raw\"])\n",
    "        target_log = float(vg.iloc[i][\"y_log\"])\n",
    "\n",
    "        X_seq.append(seq)\n",
    "        X_static.append(vg.iloc[i][static_cols].to_numpy(dtype=np.float32))\n",
    "\n",
    "        if USE_LOG_TARGET:\n",
    "            y_out.append(target_log)\n",
    "        else:\n",
    "            y_out.append(target_raw)\n",
    "\n",
    "        meta_rows.append((pid, vg.iloc[i][\"date\"]))\n",
    "\n",
    "        win = g_feats[max(0, n_before - NN_WINDOW_W):n_before]\n",
    "        nn_rows.append({\n",
    "            \"player_id\": pid,\n",
    "            \"valuation_date\": vg.iloc[i][\"date\"],\n",
    "            \"y_raw\": target_raw,\n",
    "            \"y_log\": target_log,\n",
    "            **vg.iloc[i][static_cols].to_dict(),\n",
    "            **{f\"mean_{f}\": win[:, j].mean() for j, f in enumerate(GAME_FEATURES)},\n",
    "            **{f\"sum_{f}\": win[:, j].sum() for j, f in enumerate(GAME_FEATURES)},\n",
    "        })\n",
    "\n",
    "\n",
    "X_seq = np.asarray(X_seq, dtype=np.float32)\n",
    "X_static = np.asarray(X_static, dtype=np.float32)\n",
    "y_out = np.asarray(y_out, dtype=np.float32)\n",
    "\n",
    "meta = pd.DataFrame(meta_rows, columns=[\"player_id\", \"valuation_date\"])\n",
    "tabular_df = pd.DataFrame(nn_rows)\n",
    "\n",
    "# Optional downsampling\n",
    "if MAX_SAMPLES and len(tabular_df) > MAX_SAMPLES:\n",
    "    idx = np.random.default_rng(0).choice(len(tabular_df), MAX_SAMPLES, replace=False)\n",
    "    tabular_df = tabular_df.iloc[idx]\n",
    "    X_seq = X_seq[idx]\n",
    "    X_static = X_static[idx]\n",
    "    y_out = y_out[idx]\n",
    "    meta = meta.iloc[idx]\n",
    "\n",
    "# ----------------------------\n",
    "# Save outputs (CSV + NPZ)\n",
    "# ----------------------------\n",
    "tabular_df.to_csv(OUT_DIR / \"nn_tabular_dataset.csv\", index=False)\n",
    "meta.to_csv(OUT_DIR / \"meta.csv\", index=False)\n",
    "\n",
    "np.savez_compressed(\n",
    "    OUT_DIR / \"rnn_dataset.npz\",\n",
    "    X_seq=X_seq,\n",
    "    X_static=X_static,\n",
    "    y=y_out,\n",
    ")\n",
    "\n",
    "print(\"Saved datasets to:\", OUT_DIR)\n",
    "print(\" -\", OUT_DIR / \"nn_tabular_dataset.csv\")\n",
    "print(\" -\", OUT_DIR / \"meta.csv\")\n",
    "print(\" -\", OUT_DIR / \"rnn_dataset.npz\")\n",
    "print(\"Tabular shape:\", tabular_df.shape)\n",
    "print(\"RNN X_seq:\", X_seq.shape, \"X_static:\", X_static.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
